{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "list_of_variables = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con todos los datasets:\n",
    "list_datasets_paths = sorted(glob.glob(\"Data_life_cycle/Precipitation/*.nc\"))\n",
    "# Leemos uno a uno los datasets y los almacenamos en una lista:\n",
    "lists_datasets = []\n",
    "for path in list_datasets_paths:\n",
    "    weather_data = xr.open_dataset(path)\n",
    "    lists_datasets.append(weather_data)\n",
    "# Hacemos un xr.concat(lista_datasets) \n",
    "# para tenerlos concatenados por la dimensión tiempo\n",
    "precipitation_total = xr.concat(lists_datasets, dim='time')\n",
    "list_of_variables.append(precipitation_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con todos los datasets:\n",
    "list_datasets_paths = sorted(glob.glob(\"Data_life_cycle/lowcloudcover/*.nc\"))\n",
    "# Leemos uno a uno los datasets y los almacenamos en una lista:\n",
    "lists_datasets = []\n",
    "for path in list_datasets_paths:\n",
    "    weather_data = xr.open_dataset(path)\n",
    "    lists_datasets.append(weather_data)\n",
    "# Hacemos un xr.concat(lista_datasets) \n",
    "# para tenerlos concatenados por la dimensión tiempo\n",
    "lowcloudcover_total = xr.concat(lists_datasets, dim='time')\n",
    "list_of_variables.append(lowcloudcover_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con todos los datasets:\n",
    "list_datasets_paths = sorted(glob.glob(\"Data_life_cycle/Temperature/*.nc\"))\n",
    "# Leemos uno a uno los datasets y los almacenamos en una lista:\n",
    "lists_datasets = []\n",
    "for path in list_datasets_paths:\n",
    "    weather_data = xr.open_dataset(path)\n",
    "    lists_datasets.append(weather_data)\n",
    "# Hacemos un xr.concat(lista_datasets) \n",
    "# para tenerlos concatenados por la dimensión tiempo\n",
    "temperature_total = xr.concat(lists_datasets, dim='time')\n",
    "list_of_variables.append(temperature_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con todos los datasets:\n",
    "list_datasets_paths = sorted(glob.glob(\"Data_life_cycle/snowfall/*.nc\"))\n",
    "# Leemos uno a uno los datasets y los almacenamos en una lista:\n",
    "lists_datasets = []\n",
    "for path in list_datasets_paths:\n",
    "    weather_data = xr.open_dataset(path)\n",
    "    lists_datasets.append(weather_data)\n",
    "# Hacemos un xr.concat(lista_datasets) \n",
    "# para tenerlos concatenados por la dimensión tiempo\n",
    "snowfall_total = xr.concat(lists_datasets, dim='time')\n",
    "list_of_variables.append(snowfall_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con todos los datasets:\n",
    "list_datasets_paths = sorted(glob.glob(\"Data_life_cycle/windu/*.nc\"))\n",
    "# Leemos uno a uno los datasets y los almacenamos en una lista:\n",
    "lists_datasets = []\n",
    "for path in list_datasets_paths:\n",
    "    weather_data = xr.open_dataset(path)\n",
    "    lists_datasets.append(weather_data)\n",
    "# Hacemos un xr.concat(lista_datasets) \n",
    "# para tenerlos concatenados por la dimensión tiempo\n",
    "windu_total = xr.concat(lists_datasets, dim='time')\n",
    "list_of_variables.append(windu_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con todos los datasets:\n",
    "list_datasets_paths = sorted(glob.glob(\"Data_life_cycle/windv/*.nc\"))\n",
    "# Leemos uno a uno los datasets y los almacenamos en una lista:\n",
    "lists_datasets = []\n",
    "for path in list_datasets_paths:\n",
    "    weather_data = xr.open_dataset(path)\n",
    "    lists_datasets.append(weather_data)\n",
    "# Hacemos un xr.concat(lista_datasets) \n",
    "# para tenerlos concatenados por la dimensión tiempo\n",
    "windv_total = xr.concat(lists_datasets, dim='time')\n",
    "list_of_variables.append(windv_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = xr.merge(list_of_variables)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset['Wind'] = np.sqrt(total_dataset['u10n_NON_CDM']**2 + total_dataset['v10n_NON_CDM']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = total_dataset.drop(['u10n_NON_CDM', 'v10n_NON_CDM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = total_dataset.drop(['lat', 'lon', 'realization', 'leadtime', 'forecast_reference_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'tprate': 'Precipitation', 'tas': 'Temperature',\n",
    "               'lcc_NON_CDM': 'CloudCover', 'sfrate': 'Snowfall'}\n",
    "total_dataset = total_dataset.rename(rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = total_dataset.sel(time=slice(total_dataset.time.values[0],'2010-12-11 22:00:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset_pandas = total_dataset.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset_pandas.to_csv('meteorology_house.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_paths = sorted(glob.glob(\"power_consumption*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power_consumption_2007.csv\n",
      "power_consumption_2008.csv\n",
      "power_consumption_2009.csv\n",
      "power_consumption_2010.csv\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for i in range(len(electricity_paths)):\n",
    "    print(electricity_paths[i])\n",
    "    data = pd.read_csv(electricity_paths[i])\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_consumption_total = pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_consumption_total = power_consumption_total.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2007-01-01 00:00:00', '2007-01-01 02:00:00',\n",
       "               '2007-01-01 04:00:00', '2007-01-01 06:00:00',\n",
       "               '2007-01-01 08:00:00', '2007-01-01 10:00:00',\n",
       "               '2007-01-01 12:00:00', '2007-01-01 14:00:00',\n",
       "               '2007-01-01 16:00:00', '2007-01-01 18:00:00',\n",
       "               ...\n",
       "               '2010-12-11 04:00:00', '2010-12-11 06:00:00',\n",
       "               '2010-12-11 08:00:00', '2010-12-11 10:00:00',\n",
       "               '2010-12-11 12:00:00', '2010-12-11 14:00:00',\n",
       "               '2010-12-11 16:00:00', '2010-12-11 18:00:00',\n",
       "               '2010-12-11 20:00:00', '2010-12-11 22:00:00'],\n",
       "              dtype='datetime64[ns]', name='time', length=17292, freq=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset_pandas.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2007-01-01 00:00:00', '2007-01-01 02:00:00', '2007-01-01 04:00:00',\n",
       "       '2007-01-01 06:00:00', '2007-01-01 08:00:00', '2007-01-01 10:00:00',\n",
       "       '2007-01-01 12:00:00', '2007-01-01 14:00:00', '2007-01-01 16:00:00',\n",
       "       '2007-01-01 18:00:00',\n",
       "       ...\n",
       "       '2010-12-11 04:00:00', '2010-12-11 06:00:00', '2010-12-11 08:00:00',\n",
       "       '2010-12-11 10:00:00', '2010-12-11 12:00:00', '2010-12-11 14:00:00',\n",
       "       '2010-12-11 16:00:00', '2010-12-11 18:00:00', '2010-12-11 20:00:00',\n",
       "       '2010-12-11 22:00:00'],\n",
       "      dtype='object', name='time', length=17295)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_consumption_total.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17292"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_dataset_pandas.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(power_consumption_total.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.merge(power_consumption_total, total_dataset_pandas, left_index=True, right_index=True, how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.to_csv('final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
